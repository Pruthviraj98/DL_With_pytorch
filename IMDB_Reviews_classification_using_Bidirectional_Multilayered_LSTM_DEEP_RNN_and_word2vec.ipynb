{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.7"
    },
    "colab": {
      "name": "IMDB-Reviews classification using Bidirectional Multilayered LSTM - DEEP RNN and word2vec.ipynb",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v8m1C3Ec4LH0",
        "colab_type": "text"
      },
      "source": [
        "### IMDB dataset having 50K movie reviews for natural language processing or Text analytics.\n",
        "### This is a dataset for binary sentiment classification containing substantially more data than previous benchmark datasets\n",
        "\n",
        "SOURCE: Kaggle\n",
        "link: https://www.kaggle.com/lakshmi25npathi/imdb-dataset-of-50k-movie-reviews"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2OLtWXIu4LH1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import spacy\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from spacy.lang.en.stop_words import STOP_WORDS\n",
        "from spacy import lemmatizer\n",
        "from nltk.tokenize import RegexpTokenizer\n",
        "import pandas as pd\n",
        "import gensim\n",
        "from gensim.models import Word2Vec\n",
        "from sklearn.model_selection import train_test_split\n",
        "import torch \n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "from google.colab import drive"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KFAi6BOt4OI2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "46304779-b2b9-48de-c96c-f0bee247c316"
      },
      "source": [
        "# tf.enable_eager_execution()\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ufV_V5_X4LH4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "nlp=spacy.load('en_core_web_sm', disable=['tagger', 'parser', 'ner'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4bP7Rkn_4LH6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokenizer=RegexpTokenizer(\"(\\w+\\'?\\w+?)\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nzs81_lX5Oii",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        },
        "outputId": "d3022b06-a64b-48aa-a981-6e9befe34f6c"
      },
      "source": [
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EcxKz8cp4LH8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sw1=stopwords.words(\"english\")\n",
        "sw2=STOP_WORDS\n",
        "stop_words=set(sw1).union(sw2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y3OufBrx4LH_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def tokenize(rev):\n",
        "    return(tokenizer.tokenize(str(rev).lower()))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DKoiE1mV4LIB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def remove_stop_words(rev_tokens):\n",
        "    return([tok for tok in rev_tokens if tok not in stop_words])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FSdnNruJ4LID",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def lemmatize(rev_tokens):\n",
        "    result=[]\n",
        "    for tok in rev_tokens:\n",
        "        temp=nlp(tok)\n",
        "        for tok in temp:\n",
        "            result.append(tok.lemma_)\n",
        "    return result"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IKAoHBTZ4LIF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def preprocess_pipeline(review):\n",
        "    review=tokenize(review)\n",
        "    review=remove_stop_words(review)\n",
        "    review=lemmatize(review)\n",
        "    return review"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y294FPhT4LIH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "outputId": "82787207-2e0f-4eab-aa46-9e656d059a42"
      },
      "source": [
        "df=pd.read_csv('/content/gdrive/My Drive/Colab Notebooks/IMDB Dataset.csv')\n",
        "df.head(2)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>One of the other reviewers has mentioned that ...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              review sentiment\n",
              "0  One of the other reviewers has mentioned that ...  positive\n",
              "1  A wonderful little production. <br /><br />The...  positive"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ie0Ul6XP4LIK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "reviews=list(df['review'])\n",
        "sentiments=list(df['sentiment'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vAtcQeKp4LIL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "reviews=list(map(lambda x: preprocess_pipeline(x), reviews))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oTFokhm44LIN",
        "colab_type": "text"
      },
      "source": [
        "##### word embddings using word2vec from gensim"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_qouKICC4LIO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dimension=100 # will also be used in the RNN unit part \n",
        "model=Word2Vec(reviews, size=dimension, window=3, min_count=3, workers=4)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ofTkn6944LIP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d83a018b-4b0b-4123-9c2a-7ed36d6d0f79"
      },
      "source": [
        "model.sg#its CBOW not skipgram"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2swR0JNu4LIR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# tip: as soon as we train our model, we have to delete the model unless there is further training or updation required in the model because it consumes lots of memory\n",
        "# but, to use it even after deleting the model, we can use key'd vector model that holds all the info about the embedding model\n",
        "word_vec=model.wv\n",
        "del(model)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eUgqID2F4LIT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "441d88ed-79f8-42fb-c2d0-4f83679dd330"
      },
      "source": [
        "#save the vocabulary of the model\n",
        "len(word_vec.vocab)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "38859"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jpaONQZ44LIV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "b96795bb-fb50-41f9-b2c4-fc3f59e6b935"
      },
      "source": [
        "word_vec.similar_by_word(word=\"bad\", topn=10)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('terrible', 0.747195303440094),\n",
              " ('horrible', 0.741730809211731),\n",
              " ('awful', 0.7321454286575317),\n",
              " ('good', 0.7019721865653992),\n",
              " ('lousy', 0.6956417560577393),\n",
              " ('suck', 0.6857665777206421),\n",
              " ('crappy', 0.64302659034729),\n",
              " ('atrocious', 0.6322519183158875),\n",
              " ('lame', 0.6303330659866333),\n",
              " ('mediocre', 0.6185406446456909)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DHatbr4L4LIX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "52a15f33-367e-4f39-ca49-e60c2eec6804"
      },
      "source": [
        "word_vec.similarity(\"good\", \"be\")"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.13662036"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UvTb7mAD4LIZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 154
        },
        "outputId": "3c3c5cdc-0875-42b8-e902-cbc27bf3b423"
      },
      "source": [
        "#now apply contextual relation with the word\n",
        "#ex: king - man + woman = queen\n",
        "#example: \n",
        "word_vec.most_similar(negative=[\"bad\"], positive=[\"decent\"], topn=5)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('modest', 0.4140951633453369),\n",
              " ('solid', 0.4094703495502472),\n",
              " ('fine', 0.3787546157836914),\n",
              " ('creditable', 0.3685643672943115),\n",
              " ('workmanlike', 0.3478650748729706)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yiHG_1nQ4LIb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# from gensim.models import KeyedVectors #to store the loaded pretrained model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i09CXSEU4LId",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# model=KeyedVectors.load_word2vec_format('pretrained embedding path in .bin format', binary=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BOA6Jn2X4LIf",
        "colab_type": "text"
      },
      "source": [
        "### Build the model for sentiment analysis using RNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g-HE4QLK4LIf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#to ensure results are reproducable set these\n",
        "SEED=2031\n",
        "torch.manual_seed(SEED)\n",
        "torch.cuda.manual_seed(SEED)\n",
        "torch.backends.cudnn.deterministic=True"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qs1Su_Uz4LIh",
        "colab_type": "text"
      },
      "source": [
        "Take in the text in the review and convert into corresponding index (dictionary) for this dictionary, key'd vector from gensim is used. Using that dictionary we'd convert all the words in our text corpus as indices and then we pass those indices through the RNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vfMOPcOB4LIh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def convWordInd(embedding_model, review):\n",
        "    indice_rev=[]\n",
        "    for word in review:\n",
        "        try:\n",
        "            indice_rev.append(embedding_model.vocab[word].index)\n",
        "        except:\n",
        "            pass\n",
        "    return torch.tensor(indice_rev)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MpN2E6af4LIj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "review_indexes=list(map(lambda x: convWordInd(word_vec, x), reviews))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wpDck-7m4LIl",
        "colab_type": "text"
      },
      "source": [
        "Passing the data to nn as batches. When it is done so, all the sentance should have the same length For that, all the statements are padded with the padding value (len of longest statement in the batch). So, the padding value is appended to the end of the shorter statements (that is the index value that's why it is done so)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qj8HSNy94LIl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "838221b9-c354-4b00-b0f6-c02f95da690d"
      },
      "source": [
        "pad_value=len(word_vec.index2word) #used later during RNN param initialization\n",
        "pad_value #this is the length of the longest review in the batch"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "38859"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KTgjEvsA4LIn",
        "colab_type": "text"
      },
      "source": [
        "#### BUILD THE RNN MODEL\n",
        "\n",
        "layers:\n",
        "1. Embedding layer - input - indexed reviews and convert to embedded format \n",
        "2. RNN unit - input - embedded representation\n",
        "3. Fully connected unit (dense)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CT_gsAol4LIn",
        "colab_type": "text"
      },
      "source": [
        "Embedding layer :Word embeddings are already created using gensim and these pre-trained embeddings are used within our nn. For that first extract the weights that the gensim model has learned while training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iaspzxNQ4LIo",
        "colab_type": "text"
      },
      "source": [
        "RNN Model-for training and evaluation.\n",
        "After that the  dense layer is declared\n",
        "\n",
        "forward function: for data when passed onto the model, for each batch x, with size (max(len(sentances)*len(batch)))\n",
        "\n",
        "pytorch internally converts the indexed representation which we passed to one hot encoding.\n",
        "\n",
        "##### NOTE\n",
        "In the forward pass function, batch of reviews and the len of each review (text length) is passed. But, in case of RNN, each and every review must have same length. However, it is not required that the model to read that padded values. Hence we use the pytorch inbuilt function called \"packpaddedsequence\". It packs the padded values automatically and internally handles for us. \n",
        "\n",
        "So the packed sequence is passed through the RNN and after passing through the RNN, the packed sequence is unlocked. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GivVq05T4LIo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "embed_weights=torch.Tensor(word_vec.vectors)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4AFuAnoh4LIq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class RNN(nn.Module):\n",
        "    def __init__(self, inp_dim, embed_dim, hidden_dim, out_dim, n_layers, bidirectional, dropout, embed_weights):\n",
        "        super().__init__()\n",
        "        self.embedding_layer=nn.Embedding.from_pretrained(embed_weights)\n",
        "        self.rnn=nn.LSTM(embed_dim, hidden_dim, num_layers=n_layers, bidirectional=bidirectional, dropout=dropout)\n",
        "        self.dense=nn.Linear(hidden_dim*2, out_dim)#ip layer is hid_layer*2 because in case of bidirectional RNN, there are 2 hidden layer o/p\n",
        "        self.dropout=nn.Dropout(dropout)#never use dropout in the ip or op layers but in the intermediate layers\n",
        "        \n",
        "    def forward(self, x, text_lens):\n",
        "        embedded=self.embedding_layer(x)\n",
        "        packed_embed=nn.utils.rnn.pack_padded_sequence(embedded, text_lens)\n",
        "        packed_out, (hidden, cell)=self.rnn(packed_embed) #output size=[text_len, batch_size, hiddendim*num of dim]\n",
        "        #output, output_lens=nn.utils.rnn.pad_packed_sequence(packed_out) commented as output is not used here \n",
        "        #bdirlstm consists [f0, b0, f1, b1, ..... fn, bn]\n",
        "        #so, concatinating the last two hidden state (forward and backward) from the last layer, it is passed to linear layer \n",
        "        hidden =self.dropout(torch.cat((hidden[-2, :, :], hidden[-1, :, :]), dim=1))\n",
        "        return self.dense(hidden.squeeze(0))        "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KubDopWv4LIt",
        "colab_type": "text"
      },
      "source": [
        "Define the parameters for the  RNN class and create the objects of the  RNN Class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RXZB6cWT4LIt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#updating the hyperparameters\n",
        "inp_dim=pad_value\n",
        "embed_dim=dimension\n",
        "hidden_dim=256\n",
        "output_dim=1\n",
        "n_layers=2\n",
        "bidirectional=True\n",
        "dropout=0.5"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "va13bkOr4LIu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        },
        "outputId": "751c14d3-f10d-447c-da39-9803d1f2103f"
      },
      "source": [
        "model=RNN(inp_dim, embed_dim, hidden_dim, output_dim, n_layers, bidirectional, dropout, embed_weights)\n",
        "model"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RNN(\n",
              "  (embedding_layer): Embedding(38859, 100)\n",
              "  (rnn): LSTM(100, 256, num_layers=2, dropout=0.5, bidirectional=True)\n",
              "  (dense): Linear(in_features=512, out_features=1, bias=True)\n",
              "  (dropout): Dropout(p=0.5, inplace=False)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "brt94zxS4LIw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizer=optim.Adam(model.parameters())\n",
        "loss_function=nn.BCEWithLogitsLoss()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g-mB5YHo4LIy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "64803f92-6e98-48c3-89d9-6929f8155d64"
      },
      "source": [
        "device=torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "device"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0xLTjEVq4LI0",
        "colab_type": "text"
      },
      "source": [
        "#### prepare the data for :\n",
        "\n",
        "    a. Training\n",
        "\n",
        "    b. Validation\n",
        "    \n",
        "    c. Testing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e_0EYjvV4LI0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b203b266-c3bd-4476-e0e0-7d6259dd3a13"
      },
      "source": [
        "#binary encoding the y vals\n",
        "sentiments=[0 if label == 'negative' else 1 for label in sentiments]\n",
        "sentiments[:5]"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1, 1, 1, 0, 1]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4e_O7Ttq4LI2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train, X_test, Y_train, Y_test=train_test_split(review_indexes, sentiments, test_size=0.25)\n",
        "X_train, X_val, Y_train, Y_val=train_test_split(X_train, Y_train, test_size=0.2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N7MbzvZl4LI3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#now batches out of entire dataset is prepared\n",
        "batch_size=128\n",
        "def iterate_func(x, y):\n",
        "    size=len(x)\n",
        "    permute=np.random.permutation(size) #for creating the random blocks from the list of reviews\n",
        "    iterator=[]\n",
        "    for i in range(0, size, batch_size): #from 0 to size stepping from batch size\n",
        "        indices=permute[i: i+batch_size]\n",
        "        batch={}\n",
        "        batch[\"text\"]=[x[i] for i in indices]\n",
        "        batch[\"label\"]=[y[i] for i in indices]\n",
        "        #sort the texts based on their lengths\n",
        "        batch[\"text\"], batch[\"label\"]=zip(*sorted(zip(batch[\"text\"], batch[\"label\"]), key=lambda x: len(x[0]), reverse=True))\n",
        "        batch[\"length\"]=[len(rev) for rev in batch[\"text\"]]\n",
        "        batch[\"length\"]=torch.IntTensor(batch[\"length\"])\n",
        "        #Now, reviews are padded in each batch and are passed into the model. \n",
        "        #For padding, pytorch offers the method within its nn module\n",
        "        batch[\"text\"]=torch.nn.utils.rnn.pad_sequence(batch[\"text\"], batch_first=True).t()#transpose is performed so that it is accepted into rnn\n",
        "        batch[\"label\"]=torch.Tensor(batch[\"label\"])\n",
        "        \n",
        "        #now pushing all to the gpu\n",
        "        batch[\"text\"]=batch[\"text\"].to(device)\n",
        "        batch[\"label\"]=batch[\"label\"].to(device)\n",
        "        batch[\"length\"]=batch[\"length\"].to(device)\n",
        "        \n",
        "        iterator.append(batch)\n",
        "        \n",
        "    return iterator"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LNVok1VR4LI5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_iter=iterate_func(X_train, Y_train)\n",
        "val_iter=iterate_func(X_val, Y_val)\n",
        "test_iter=iterate_func(X_test, Y_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZHOVUSzi4LI6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model=model.to(device)\n",
        "criterion=loss_function.to(device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WJeeCLOP4LI8",
        "colab_type": "text"
      },
      "source": [
        "#### defining a function to know the accuracy subsequently"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aHYBVSJ44LI8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def binary_acc(preds, y):\n",
        "    round_preds=torch.round(torch.sigmoid(preds))\n",
        "    pos=(round_preds==y).float()\n",
        "    accuracy=pos.sum()/len(pos)\n",
        "    return accuracy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Csrst3p4LI-",
        "colab_type": "text"
      },
      "source": [
        "#### defining the function to train the model \n",
        "set the loss and accuracies as false from the previous use and set the model to training mode"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z98z_N7o4LI-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(model, iterator, optimizer, criterion):\n",
        "    epoch_loss=0\n",
        "    epoch_accuracy=0\n",
        "    model.train()\n",
        "    \n",
        "    for batch in iterator:\n",
        "        optimizer.zero_grad()\n",
        "        predictions=model(batch[\"text\"], batch[\"length\"]).squeeze(1)\n",
        "        loss=criterion(predictions, batch[\"label\"])\n",
        "        accuracy=binary_acc(predictions, batch[\"label\"])\n",
        "        loss.backward()\n",
        "        optimizer.step() #updates the weight for the model\n",
        "        epoch_loss+=loss.item()\n",
        "        epoch_accuracy+=accuracy.item()\n",
        "    \n",
        "    #return the average epoch loss and iterator\n",
        "    return(epoch_loss/len(iterator), epoch_accuracy/len(iterator))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p-xqF8Rm4LJA",
        "colab_type": "text"
      },
      "source": [
        "#### defining the function to Test the model\n",
        "set the loss and accuracies as false from the previous use and set the model to evaluation mode"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X6IwBa3x4LJA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def evaluator(model, iterator, criterion):\n",
        "    epoch_loss=0\n",
        "    epoch_accuracy=0\n",
        "    model.eval()\n",
        "    #to prevent any gradient calculation with nograd is used\n",
        "    with torch.no_grad():\n",
        "        for batch in iterator:\n",
        "            predictions=model(batch[\"text\"], batch[\"length\"]).squeeze(1)\n",
        "            loss=criterion(predictions, batch[\"label\"])\n",
        "            accuracy=binary_acc(predictions, batch[\"label\"])\n",
        "            epoch_loss+=loss.item()\n",
        "            epoch_accuracy+=accuracy.item()\n",
        "\n",
        "    #return the average epoch loss and iterator\n",
        "    return(epoch_loss/len(iterator), epoch_accuracy/len(iterator))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tO6TMwrz4LJB",
        "colab_type": "text"
      },
      "source": [
        "#### Running the model and evaluation "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BuZXRqhY4LJC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 521
        },
        "outputId": "d3a22cce-4b8d-4ad6-a1d6-611240509902"
      },
      "source": [
        "epochs=10\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    train_loss, train_accuracy=train(model, train_iter, optimizer, criterion)\n",
        "    valid_loss, valid_accuracy=evaluator(model, val_iter, criterion)\n",
        "    \n",
        "    print(\"Epoch number: \", epoch)\n",
        "    print(\"Train Loss = \", train_loss, \" Train Accuracy = \", train_accuracy)\n",
        "    print(\"Validation Loss = \", valid_loss, \" Validation Accuracy = \", valid_accuracy)"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch number:  0\n",
            "Train Loss =  0.46462931937359747  Train Accuracy =  0.7737588654173181\n",
            "Validation Loss =  0.5330934958942866  Validation Accuracy =  0.724966548256955\n",
            "Epoch number:  1\n",
            "Train Loss =  0.3770504614774217  Train Accuracy =  0.8346520390916378\n",
            "Validation Loss =  0.346875739804769  Validation Accuracy =  0.8596955840870485\n",
            "Epoch number:  2\n",
            "Train Loss =  0.32868919867150326  Train Accuracy =  0.8608599292471054\n",
            "Validation Loss =  0.3099044265888505  Validation Accuracy =  0.8707418047775657\n",
            "Epoch number:  3\n",
            "Train Loss =  0.29549820854308756  Train Accuracy =  0.8771054965384463\n",
            "Validation Loss =  0.28767729891558824  Validation Accuracy =  0.8827428080267825\n",
            "Epoch number:  4\n",
            "Train Loss =  0.2856949260894288  Train Accuracy =  0.8813054079705096\n",
            "Validation Loss =  0.29537911738379524  Validation Accuracy =  0.8773555977869842\n",
            "Epoch number:  5\n",
            "Train Loss =  0.26939209439653033  Train Accuracy =  0.8893949468085106\n",
            "Validation Loss =  0.27792145160295195  Validation Accuracy =  0.8890987402301723\n",
            "Epoch number:  6\n",
            "Train Loss =  0.25772193289817646  Train Accuracy =  0.8954343973322118\n",
            "Validation Loss =  0.27736783355979594  Validation Accuracy =  0.8876421724335622\n",
            "Epoch number:  7\n",
            "Train Loss =  0.2412132219431248  Train Accuracy =  0.9035128547790202\n",
            "Validation Loss =  0.2773440939895177  Validation Accuracy =  0.8893635707386469\n",
            "Epoch number:  8\n",
            "Train Loss =  0.22179422039300836  Train Accuracy =  0.9136081561129143\n",
            "Validation Loss =  0.29800197305315634  Validation Accuracy =  0.8837603148767503\n",
            "Epoch number:  9\n",
            "Train Loss =  0.20650075724784364  Train Accuracy =  0.9205562944107867\n",
            "Validation Loss =  0.30897926703348  Validation Accuracy =  0.8838927301309877\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FEWT7od94LJE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "0d73182a-782c-45e8-dfc3-f5aa14c6f704"
      },
      "source": [
        "test_loss, test_accuracy=evaluator(model, test_iter, criterion)\n",
        "print(\"Epoch number: \", epoch)\n",
        "print(\"Test Loss = \", test_loss, \" Test Accuracy = \", test_accuracy)"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch number:  9\n",
            "Test Loss =  0.3236091924565179  Test Accuracy =  0.8800450983096142\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}