{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MNIST DATA SET\n",
    "\n",
    "It is the data set of hand written digits\n",
    "different handwritten forms of different digits\n",
    "This needs the DNN to learn this data \n",
    "\n",
    "This data set is a  multiclass dataset. Here, we use softmax function as an activation function\n",
    "Here we dont use the Sigmoid function because, Sigmoid function is predominately helpful in the binary classifications.\n",
    "It is again available under the hood of pytorch.\n",
    "\n",
    "The MNIST data is being inputted into the neural network as this way:\n",
    "\n",
    "The images contained in the database are 28*28 pixels i.e. there are 784 pixels to be analysed. \n",
    "That means the input can be 784 input nodes to the DNN. \n",
    "Performance theory to be known how this actual multiclass classification occurs\n",
    "\n",
    "The data to be splitted into train and test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import datasets, transforms ##contains transformations to apply on these images before supplying to the nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./MNIST\\raw\\train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|██████████████████████████████████████████████████████████████████▎| 9805824/9912422 [00:13<00:00, 1869258.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./MNIST\\raw\\train-images-idx3-ubyte.gz to ./MNIST\\raw\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./MNIST\\raw\\train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0it [00:00, ?it/s]\n",
      "  0%|                                                                                        | 0/28881 [00:00<?, ?it/s]\n",
      " 57%|█████████████████████████████████████████▍                               | 16384/28881 [00:01<00:00, 40041.25it/s]\n",
      "32768it [00:01, 26940.00it/s]                                                                                          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./MNIST\\raw\\train-labels-idx1-ubyte.gz to ./MNIST\\raw\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./MNIST\\raw\\t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0it [00:00, ?it/s]\n",
      "  0%|                                                                                      | 0/1648877 [00:00<?, ?it/s]\n",
      "  1%|▋                                                                      | 16384/1648877 [00:01<00:39, 40952.06it/s]\n",
      "  2%|█▍                                                                     | 32768/1648877 [00:01<00:39, 40441.20it/s]\n",
      "  3%|██                                                                     | 49152/1648877 [00:01<00:37, 42521.11it/s]\n",
      "  4%|██▊                                                                    | 65536/1648877 [00:02<00:39, 39731.64it/s]\n",
      "  5%|███▉                                                                   | 90112/1648877 [00:02<00:35, 44086.56it/s]\n",
      "  6%|████▌                                                                 | 106496/1648877 [00:03<00:36, 42505.79it/s]\n",
      "  7%|█████▏                                                                | 122880/1648877 [00:03<00:36, 41795.65it/s]\n",
      "  9%|██████▎                                                               | 147456/1648877 [00:04<00:32, 46239.93it/s]\n",
      " 10%|██████▉                                                               | 163840/1648877 [00:04<00:33, 43967.97it/s]\n",
      " 11%|███████▋                                                              | 180224/1648877 [00:04<00:34, 43106.11it/s]\n",
      " 12%|████████▋                                                             | 204800/1648877 [00:05<00:30, 46799.11it/s]\n",
      " 13%|█████████▍                                                            | 221184/1648877 [00:05<00:32, 44542.86it/s]\n",
      " 14%|██████████                                                            | 237568/1648877 [00:06<00:32, 44001.82it/s]\n",
      " 16%|███████████▏                                                          | 262144/1648877 [00:06<00:29, 47095.89it/s]\n",
      " 17%|███████████▊                                                          | 278528/1648877 [00:06<00:30, 44678.04it/s]\n",
      " 18%|████████████▊                                                         | 303104/1648877 [00:07<00:27, 48658.43it/s]\n",
      " 20%|█████████████▉                                                        | 327680/1648877 [00:07<00:25, 51277.26it/s]\n",
      " 21%|██████████████▌                                                       | 344064/1648877 [00:08<00:26, 49472.25it/s]\n",
      " 22%|███████████████▋                                                      | 368640/1648877 [00:08<00:23, 53962.09it/s]\n",
      " 24%|████████████████▋                                                     | 393216/1648877 [00:08<00:22, 56045.07it/s]\n",
      " 25%|█████████████████▋                                                    | 417792/1648877 [00:09<00:21, 56979.77it/s]\n",
      " 27%|██████████████████▊                                                   | 442368/1648877 [00:09<00:20, 57609.89it/s]\n",
      " 29%|████████████████████▏                                                 | 475136/1648877 [00:10<00:18, 63404.87it/s]\n",
      " 30%|█████████████████████▏                                                | 499712/1648877 [00:10<00:18, 61682.21it/s]\n",
      " 32%|██████████████████████▌                                               | 532480/1648877 [00:10<00:16, 66219.02it/s]\n",
      " 34%|███████████████████████▋                                              | 557056/1648877 [00:11<00:16, 65001.56it/s]\n",
      " 36%|█████████████████████████                                             | 589824/1648877 [00:11<00:14, 71577.99it/s]\n",
      " 38%|██████████████████████████▍                                           | 622592/1648877 [00:12<00:13, 75297.43it/s]\n",
      " 39%|███████████████████████████▍                                          | 647168/1648877 [00:12<00:14, 70197.52it/s]\n",
      " 41%|████████████████████████████▊                                         | 679936/1648877 [00:12<00:13, 72667.84it/s]\n",
      " 43%|██████████████████████████████▎                                       | 712704/1648877 [00:13<00:12, 74921.72it/s]\n",
      " 45%|███████████████████████████████▋                                      | 745472/1648877 [00:13<00:11, 76498.75it/s]\n",
      " 47%|█████████████████████████████████                                     | 778240/1648877 [00:14<00:11, 77169.36it/s]\n",
      "9920512it [00:30, 1869258.26it/s]                                                                                      \n",
      " 52%|████████████████████████████████████▏                                 | 851968/1648877 [00:14<00:09, 82900.89it/s]\n",
      " 54%|█████████████████████████████████████▌                                | 884736/1648877 [00:15<00:09, 81085.69it/s]\n",
      " 56%|███████████████████████████████████████▎                              | 925696/1648877 [00:15<00:08, 86571.95it/s]\n",
      " 58%|████████████████████████████████████████▋                             | 958464/1648877 [00:16<00:08, 83903.47it/s]\n",
      " 61%|██████████████████████████████████████████▍                           | 999424/1648877 [00:16<00:07, 88017.33it/s]\n",
      " 63%|███████████████████████████████████████████▌                         | 1040384/1648877 [00:16<00:06, 94146.25it/s]\n",
      " 65%|████████████████████████████████████████████▉                        | 1073152/1648877 [00:17<00:05, 99548.14it/s]\n",
      " 68%|█████████████████████████████████████████████▉                      | 1114112/1648877 [00:17<00:05, 103133.16it/s]\n",
      " 70%|███████████████████████████████████████████████▋                    | 1155072/1648877 [00:17<00:04, 101689.92it/s]\n",
      " 73%|█████████████████████████████████████████████████▎                  | 1196032/1648877 [00:18<00:04, 100851.56it/s]\n",
      " 76%|███████████████████████████████████████████████████▎                | 1245184/1648877 [00:18<00:03, 105957.04it/s]\n",
      " 78%|█████████████████████████████████████████████████████               | 1286144/1648877 [00:19<00:03, 104096.28it/s]\n",
      " 81%|███████████████████████████████████████████████████████             | 1335296/1648877 [00:19<00:02, 108396.08it/s]\n",
      " 84%|█████████████████████████████████████████████████████████▍          | 1392640/1648877 [00:20<00:02, 116277.38it/s]\n",
      " 88%|███████████████████████████████████████████████████████████▊        | 1449984/1648877 [00:20<00:01, 122509.19it/s]\n",
      " 93%|███████████████████████████████████████████████████████████████▌    | 1540096/1648877 [00:20<00:00, 141300.52it/s]\n",
      " 99%|███████████████████████████████████████████████████████████████████▏| 1630208/1648877 [00:21<00:00, 158479.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./MNIST\\raw\\t10k-images-idx3-ubyte.gz to ./MNIST\\raw\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./MNIST\\raw\\t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "0it [00:00, ?it/s]\n",
      "\n",
      "  0%|                                                                                         | 0/4542 [00:00<?, ?it/s]\n",
      "\n",
      "8192it [00:00, 9521.97it/s]                                                                                            "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./MNIST\\raw\\t10k-labels-idx1-ubyte.gz to ./MNIST\\raw\n",
      "Processing...\n",
      "Done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "1654784it [00:34, 158479.64it/s]                                                                                       "
     ]
    }
   ],
   "source": [
    "transform=transforms.Compose([transforms.ToTensor(),\n",
    "                              transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))#here the first tuple, to normalize all channel with means of, second is SD\n",
    "                             ]) ## ToTensor converts the image to the tensor and characterizes the image as\n",
    "                                    ##Channel (C), Height (H), Width(W)\n",
    "    ## using the values -1, 1 reduces the skewness of the data, hence we apply the normalizations\n",
    "training_dataset=datasets.MNIST(root='./', train=True, download=True, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset MNIST\n",
       "    Number of datapoints: 60000\n",
       "    Root location: ./\n",
       "    Split: Train\n",
       "    StandardTransform\n",
       "Transform: Compose(\n",
       "               ToTensor()\n",
       "               Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))\n",
       "           )"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def im_convert(tensor):\n",
    "    image=tensor.clone().detach().numpy() #first dim= color, second= width, third =height, we know that in MNIST= it is (1, 28, 28)\n",
    "#but, to plot our image, we need (28, 28, 1). So, Transform it.\n",
    "    image= image.transpose(1, 2, 0) #swap axis 0 to 1 and 1 to 2 and 2 to 0\n",
    "#normalizaion = Z= (x-mean)/SD. So, we do this:\n",
    "    image =image*np.array((0.5, 0.5, 0.5))+ np.array((0.5, 0.5, 0.5))\n",
    "    image=image.clip(0, 1) #to ensure the values are in betn 0 and 1\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we use training loader to import the dataset that convert the data to batches\n",
    "training_loader=torch.utils.data.DataLoader(dataset=training_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
