{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IMDB dataset having 50K movie reviews for natural language processing or Text analytics.\n",
    "### This is a dataset for binary sentiment classification containing substantially more data than previous benchmark datasets\n",
    "\n",
    "SOURCE: Kaggle\n",
    "link: https://www.kaggle.com/lakshmi25npathi/imdb-dataset-of-50k-movie-reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "from spacy import lemmatizer\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "import pandas as pd\n",
    "import gensim\n",
    "from gensim.models import Word2Vec\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp=spacy.load('en_core_web_sm', disable=['tagger', 'parser', 'ner'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer=RegexpTokenizer(\"(\\w+\\'?\\w+?)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "sw1=stopwords.words(\"english\")\n",
    "sw2=STOP_WORDS\n",
    "stop_words=set(sw1).union(sw2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(rev):\n",
    "    return(tokenizer.tokenize(str(rev).lower()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stop_words(rev_tokens):\n",
    "    return([tok for tok in rev_tokens if tok not in stop_words])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize(rev_tokens):\n",
    "    result=[]\n",
    "    for tok in rev_tokens:\n",
    "        temp=nlp(tok)\n",
    "        for tok in temp:\n",
    "            result.append(tok.lemma_)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_pipeline(review):\n",
    "    review=tokenize(review)\n",
    "    review=remove_stop_words(review)\n",
    "    review=lemmatize(review)\n",
    "    return review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  One of the other reviewers has mentioned that ...  positive\n",
       "1  A wonderful little production. <br /><br />The...  positive"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv('IMDB dataset.csv')\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews=list(df['review'])\n",
    "sentiments=list(df['sentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews=list(map(lambda x: preprocess_pipeline(x), reviews))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### word embddings using word2vec from gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "dimension=100 # will also be used in the RNN unit part \n",
    "model=Word2Vec(reviews, size=dimension, window=3, min_count=3, workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.sg#its CBOW not skipgram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tip: as soon as we train our model, we have to delete the model unless there is further training or updation required in the model because it consumes lots of memory\n",
    "# but, to use it even after deleting the model, we can use key'd vector model that holds all the info about the embedding model\n",
    "word_vec=model.wv\n",
    "del(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38859"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#save the vocabulary of the model\n",
    "len(word_vec.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('terrible', 0.7415202856063843),\n",
       " ('horrible', 0.7338898181915283),\n",
       " ('awful', 0.7099471688270569),\n",
       " ('suck', 0.6869287490844727),\n",
       " ('lousy', 0.6774225831031799),\n",
       " ('good', 0.6722398996353149),\n",
       " ('lame', 0.6422511339187622),\n",
       " ('crappy', 0.6361573934555054),\n",
       " ('mediocre', 0.6220316886901855),\n",
       " ('horrid', 0.6045772433280945)]"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vec.similar_by_word(word=\"bad\", topn=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.14868656"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vec.similarity(\"good\", \"be\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('solid', 0.4193841814994812),\n",
       " ('fine', 0.3851555585861206),\n",
       " ('workmanlike', 0.37039029598236084),\n",
       " ('modest', 0.3677048087120056),\n",
       " ('creditable', 0.3613351583480835)]"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#now apply contextual relation with the word\n",
    "#ex: king - man + woman = queen\n",
    "#example: \n",
    "word_vec.most_similar(negative=[\"bad\"], positive=[\"decent\"], topn=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from gensim.models import KeyedVectors #to store the loaded pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model=KeyedVectors.load_word2vec_format('pretrained embedding path in .bin format', binary=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the model for sentiment analysis using RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to ensure results are reproducable set these\n",
    "SEED=2031\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic=True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take in the text in the review and convert into corresponding index (dictionary) for this dictionary, key'd vector from gensim is used. Using that dictionary we'd convert all the words in our text corpus as indices and then we pass those indices through the RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convWordInd(embedding_model, review):\n",
    "    indice_rev=[]\n",
    "    for word in review:\n",
    "        try:\n",
    "            indice_rev.append(embedding_model.vocab[word].index)\n",
    "        except:\n",
    "            pass\n",
    "    return torch.tensor(indice_rev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_indexes=list(map(lambda x: convWordInd(word_vec, x), reviews))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Passing the data to nn as batches. When it is done so, all the sentance should have the same length For that, all the statements are padded with the padding value (len of longest statement in the batch). So, the padding value is appended to the end of the shorter statements (that is the index value that's why it is done so)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38859"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pad_value=len(word_vec.index2word) #used later during RNN param initialization\n",
    "pad_value #this is the length of the longest review in the batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BUILD THE RNN MODEL\n",
    "\n",
    "layers:\n",
    "1. Embedding layer - input - indexed reviews and convert to embedded format \n",
    "2. RNN unit - input - embedded representation\n",
    "3. Fully connected unit (dense)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Embedding layer :Word embeddings are already created using gensim and these pre-trained embeddings are used within our nn. For that first extract the weights that the gensim model has learned while training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RNN Model-for training and evaluation.\n",
    "After that the  dense layer is declared\n",
    "\n",
    "forward function: for data when passed onto the model, for each batch x, with size (max(len(sentances)*len(batch)))\n",
    "\n",
    "pytorch internally converts the indexed representation which we passed to one hot encoding.\n",
    "\n",
    "##### NOTE\n",
    "In the forward pass function, batch of reviews and the len of each review (text length) is passed. But, in case of RNN, each and every review must have same length. However, it is not required that the model to read that padded values. Hence we use the pytorch inbuilt function called \"packpaddedsequence\". It packs the padded values automatically and internally handles for us. \n",
    "\n",
    "So the packed sequence is passed through the RNN and after passing through the RNN, the packed sequence is unlocked. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_weights=torch.Tensor(word_vec.vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self, inp_dim, embed_dim, hidden_dim, out_dim, embed_weights):\n",
    "        super().__init__()\n",
    "        self.embedding_layer=nn.Embedding.from_pretrained(embed_weights)\n",
    "        self.rnn=nn.RNN(embed_dim, hidden_dim)\n",
    "        self.den=nn.Linear(hidden_dim, out_dim)\n",
    "    def forward(self, x, text_lens):\n",
    "        #x[size= sent len, batch size].. this is the input shape\n",
    "        embedded=self.embedding_layer(x) #[sent len, batch_size, embedding_size] this is the  shape of the embedding\n",
    "        packed_embedded=nn.utils.rnn.pack_padded_sequence(embedded, text_lens)\n",
    "        packed_out, hidden=self.rnn(packed_embedded)#[sentance len, batch_size, hidden_dim] is  the size of packed_output and for hidden state - [1, batch_size, hidden dimension]\n",
    "#in case of need of the packed sequences to be unlocked:\n",
    "        output, output_lens=nn.utils.rnn.pad_packed_sequence(packed_out)\n",
    "#but here, only the hidden values is needed to pass through the dense layer\n",
    "        #so, squeeze the layer to remove that extra dimension within the  hidden state\n",
    "        return self.den(hidden.squeeze(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the parameters for the  RNN class and create the objects of the  RNN Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim=pad_value\n",
    "emb_dim=dimension#declared above somewhere\n",
    "hidden_dim=256\n",
    "out_dim=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RNN(\n",
       "  (embedding_layer): Embedding(38859, 100)\n",
       "  (rnn): RNN(100, 256)\n",
       "  (den): Linear(in_features=256, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model=RNN(input_dim, emb_dim, hidden_dim, out_dim, embed_weights)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer=optim.SGD(model.parameters(), lr=0.003)\n",
    "loss_function=nn.BCEWithLogitsLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device=torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### prepare the data for :\n",
    "\n",
    "    a. Training\n",
    "\n",
    "    b. Validation\n",
    "    \n",
    "    c. Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 1, 1, 0, 1]"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#binary encoding the y vals\n",
    "sentiments=[0 if label == 'negative' else 1 for label in sentiments]\n",
    "sentiments[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test=train_test_split(review_indexes, sentiments, test_size=0.25)\n",
    "X_train, X_val, Y_train, Y_val=train_test_split(X_train, Y_train, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now batches out of entire dataset is prepared\n",
    "batch_size=128\n",
    "def iterate_func(x, y):\n",
    "    size=len(x)\n",
    "    permute=np.random.permutation(size) #for creating the random blocks from the list of reviews\n",
    "    iterator=[]\n",
    "    for i in range(0, size, batch_size): #from 0 to size stepping from batch size\n",
    "        indices=permute[i: i+batch_size]\n",
    "        batch={}\n",
    "        batch[\"text\"]=[x[i] for i in indices]\n",
    "        batch[\"label\"]=[y[i] for i in indices]\n",
    "        #sort the texts based on their lengths\n",
    "        batch[\"text\"], batch[\"label\"]=zip(*sorted(zip(batch[\"text\"], batch[\"label\"]), key=lambda x: len(x[0]), reverse=True))\n",
    "        batch[\"length\"]=[len(rev) for rev in batch[\"text\"]]\n",
    "        batch[\"length\"]=torch.IntTensor(batch[\"length\"])\n",
    "        #Now, reviews are padded in each batch and are passed into the model. \n",
    "        #For padding, pytorch offers the method within its nn module\n",
    "        batch[\"text\"]=torch.nn.utils.rnn.pad_sequence(batch[\"text\"], batch_first=True).t()#transpose is performed so that it is accepted into rnn\n",
    "        batch[\"label\"]=torch.Tensor(batch[\"label\"])\n",
    "        \n",
    "        #now pushing all to the gpu\n",
    "        batch[\"text\"]=batch[\"text\"].to(device)\n",
    "        batch[\"label\"]=batch[\"label\"].to(device)\n",
    "        batch[\"length\"]=batch[\"length\"].to(device)\n",
    "        \n",
    "        iterator.append(batch)\n",
    "        \n",
    "    return iterator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iter=iterate_func(X_train, Y_train)\n",
    "val_iter=iterate_func(X_val, Y_val)\n",
    "test_iter=iterate_func(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=model.to(device)\n",
    "criterion=loss_function.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### defining a function to know the accuracy subsequently"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_acc(preds, y):\n",
    "    round_preds=torch.round(torch.sigmoid(preds))\n",
    "    pos=(round_preds==y).float()\n",
    "    accuracy=pos.sum()/len(pos)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### defining the function to train the model \n",
    "set the loss and accuracies as false from the previous use and set the model to training mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, iterator, optimizer, criterion):\n",
    "    epoch_loss=0\n",
    "    epoch_accuracy=0\n",
    "    model.train()\n",
    "    \n",
    "    for batch in iterator:\n",
    "        optimizer.zero_grad()\n",
    "        predictions=model(batch[\"text\"], batch[\"length\"]).squeeze(1)\n",
    "        loss=criterion(predictions, batch[\"label\"])\n",
    "        accuracy=binary_acc(predictions, batch[\"label\"])\n",
    "        loss.backward()\n",
    "        optimizer.step() #updates the weight for the model\n",
    "        epoch_loss+=loss.item()\n",
    "        epoch_accuracy+=accuracy.item()\n",
    "    \n",
    "    #return the average epoch loss and iterator\n",
    "    return(epoch_loss/len(iterator), epoch_accuracy/len(iterator))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### defining the function to Test the model\n",
    "set the loss and accuracies as false from the previous use and set the model to evaluation mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluator(model, iterator, criterion):\n",
    "    epoch_loss=0\n",
    "    epoch_accuracy=0\n",
    "    model.eval()\n",
    "    #to prevent any gradient calculation with nograd is used\n",
    "    with torch.no_grad():\n",
    "        for batch in iterator:\n",
    "            predictions=model(batch[\"text\"], batch[\"length\"]).squeeze(1)\n",
    "            loss=criterion(predictions, batch[\"label\"])\n",
    "            accuracy=binary_acc(predictions, batch[\"label\"])\n",
    "            epoch_loss+=loss.item()\n",
    "            epoch_accuracy+=accuracy.item()\n",
    "\n",
    "    #return the average epoch loss and iterator\n",
    "    return(epoch_loss/len(iterator), epoch_accuracy/len(iterator))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Running the model and evaluation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch number:  0\n",
      "Train Loss =  0.575541971592193  Train Accuracy =  0.7060948582405739\n",
      "Validation Loss =  0.5174620601080232  Validation Accuracy =  0.7494842773776943\n",
      "Epoch number:  1\n",
      "Train Loss =  0.44786902539273526  Train Accuracy =  0.7992464539852548\n",
      "Validation Loss =  0.412110616089934  Validation Accuracy =  0.8267381241766073\n",
      "Epoch number:  2\n",
      "Train Loss =  0.424059035042499  Train Accuracy =  0.818062943346957\n",
      "Validation Loss =  0.4688831315202228  Validation Accuracy =  0.7866929638183723\n",
      "Epoch number:  3\n",
      "Train Loss =  0.4816316267277332  Train Accuracy =  0.7761303191489362\n",
      "Validation Loss =  0.5920464063094835  Validation Accuracy =  0.6814855599807481\n",
      "Epoch number:  4\n",
      "Train Loss =  0.47332527510663297  Train Accuracy =  0.7838541667512122\n",
      "Validation Loss =  0.4008926117824296  Validation Accuracy =  0.8312263044260316\n"
     ]
    }
   ],
   "source": [
    "epochs=5\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    train_loss, train_accuracy=train(model, train_iter, optimizer, criterion)\n",
    "    valid_loss, valid_accuracy=evaluator(model, val_iter, criterion)\n",
    "    \n",
    "    print(\"Epoch number: \", epoch)\n",
    "    print(\"Train Loss = \", train_loss, \" Train Accuracy = \", train_accuracy)\n",
    "    print(\"Validation Loss = \", valid_loss, \" Validation Accuracy = \", valid_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch number:  4\n",
      "Test Loss =  0.39689796554798984  Test Accuracy =  0.8333978683364635\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_accuracy=evaluator(model, test_iter, criterion)\n",
    "print(\"Epoch number: \", epoch)\n",
    "print(\"Test Loss = \", test_loss, \" Test Accuracy = \", test_accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
